---
title: "Project 1 Code"
author: "Seth Bitney, Sarah Hall, Nathan Koh, Hannah Richardson"
date: "2024-10-27"
output: html_document
---

```{r setup, include=TRUE}
library(tidyverse)
data <- read.csv('diamonds4.csv')
```

## Individual Variable Code

Here is a place to put any code or visualizations we need to perform  

### Color

```{r}
#reorder bar chart so that it goes from near-colorless (J,I,H,G) to colorless (F,E,D)
data$color <-factor(data$color, levels =c("J","I","H","G","F","E","D"))

#plot the bar chart
ggplot(data, aes(x=color,y=price))+
  geom_bar(stat="identity", fill = "tomato3")+
  scale_y_continuous(labels = scales::comma)+
  theme(axis.text.x = element_text(),
        plot.title=element_text(hjust = 0.5))+
  labs(x="Color",y="Price", title = "Distribution of Diamond Price by Color Grade")

```
 *Fig 1. Distribution of Diamonds *\

From the bar chart, we can come to the following conclusions based on these initial observations.  \

Color D has the highest cumulative price. According to Blue Nile, diamond prices decline or increase in alphabetical order, so D diamonds should have the most cost cumulatively. Note that D, E, and F color diamonds are all rare, colorless diamonds that are high quality with a pure icy look.\

Similarly, color J has the lowest cumulative price due to it being at the bottom of the grading scale. These are considered to have no discernible color, but great value for the quality.
\
  

However, when looking at the other color grades, we see a discrepancy from Blue Nile's claim that prices increase or decrease in alphabetical order. The cumulative prices for grade G requires additional research as it can be due to other factors (which may not necessarily be relevant to Color vs Price). 
\
  
**Sarah's notes** 
I am concerned, like further down with clarity, that the bar chart is showing a sum of diamond prices for each category without touching on the number of diamonds per color. Should this be included in this analysis?
**end of Sarah's notes**

To provide additional context regarding the color variable, we can create a new dataframe which shows the proportion of the number of diamonds in each color group, the average carat, average price, and how frequent it is within the dataset.  

```{r}
Data2<-data %>% 
  group_by(color) %>% 
  summarize(avg.prices=mean(price),avg.carat=mean(carat),total = n()) 

grouped <-table(data$color)
totals<-sum(grouped)

color_percent<-(grouped / totals)*100

new_df<-data.frame(Data2,color_percent)

new_df<-new_df[,c(1,2,3,4,6)] #removing duplicated rows for clarity
new_df #Freq is already converted to a percent.
```




```{r}
ggplot(new_df, aes(x=color,y=avg.prices))+
  geom_bar(stat="identity", fill="darkslategrey", col="white")+
  scale_y_continuous(labels = scales::comma)+
  theme(axis.text.x = element_text(),
        plot.title=element_text(hjust = 0.5))+
  labs(x="Color",y="Average Price", title = "Distribution of Average Diamond Price by Color")
```
*Fig. 2: Dataframe showing average price across each diamond color grade*\

```{r}
ggplot(new_df, aes(x=color,y=Freq))+
  geom_bar(stat="identity",fill="tomato3")+
  theme(axis.text.x = element_text(angle=0),
        plot.title=element_text(hjust = 0.5))+
  labs(x="Color",y="Frequency", title = "Frequency of Diamonds across the Color Grade Scale")
```
\
Fig 3: Bar chart showing the average prices of diamonds across color grading scale\

The bar chart portrays the average price of diamonds in each color grade from the lowest grade to highest. These are ordered similarly for ease of viewing. The following observations are seen:

1) Color J is the cheapest on average - $\$3934.089$\
2) Color D is the most expensive on average - $\$10525.155$\
3) We see a similar issue in Fig. 3 where Blue Nile's claim comes into question. Some of the reasons of why that is can be due to the following:

  a) If the diamond prices are supposed to increase or decrease in alphabetical order based on the color grading scale, there should be an indicator that prices increase or decrease across all tiers cumulatively (Fig. 1). Assuming G does, this implies that the average price of each diamond should still follow an increasing or decreasing pattern based on color grade. However, G does not. Also, the average prices for H, G, and F are also not ordered, which disproves this claim.
  
  
\
  b) Depending on the shape of the diamond, prices can fluctuate despite their color grade. According to Blue Nile, the best shapes are Radiant, Cushion, and Princess which are known to mask color the best with their multifaceted sparkle. This implies that these shapes can be more expensive despite their color grade\
  
  
  c) The type of diamond cut directly affects diamond price (ie: Astor and Ideal cuts are claimed to be most expensive due to these cuts maximizing interaction with light)\


The second claim we want to prove is if Color is the second most important variable of the 4 C's. We can represent this case by using a boxplot to show the distribution of datapoints within each color grade.\


*Note: Due to the extreme outliers across all color grades, this made it difficult to see the boxplots themselves. Due to this, two boxplots were created (Fig.4 and Fig.5) for clarity. The first boxplot contains the outliers, while the second boxplot is rescaled so that the plots themselves are visible.*

```{r }
ggplot(data,aes(x=color,y=price,fill=color))+
  geom_boxplot()+
  scale_y_continuous(labels = scales::comma)+
  theme(axis.text.x = element_text(),plot.title=element_text(hjust = 0.5))+
  labs(x="Color",y="Price", title = "Boxplot of Diamond Color Against Price, with Outliers")
```
*Fig.4: Color-Price Boxplot with Outlier Indicators*

```{r}
ggplot(data,aes(x=color,y=price,fill=color))+
  geom_boxplot(outlier.color=NA)+ylim(0,12500)+
  theme(axis.text.x = element_text(),plot.title=element_text(hjust = 0.5))+
  labs(x="Color",y="Price",title="Color to Diamond Price Distribution, without Outliers")
  
```




### Clarity

```{r}
Clarity_Table <- table(data$clarity)
round(prop.table(Clarity_Table), 4)
```
From the table above we can see that the majority of the data provided is from diamonds with a clarity classified as SI1, VS1, VS2, and SI2. 

```{r}
#Hannah's chart
ggplot(data, aes(x=clarity, y=price))+
  geom_bar(stat="identity", fill="darkslategrey")+
  scale_y_continuous(labels = scales::comma)+
  theme(axis.text.x = element_text(angle = 0),
        plot.title = element_text(hjust = 0.5))+
  labs(x="Clarity", y="Price",title="Distribution of Clarity vs Price")
```
From the graph we can see that the data from least to most expensive is as follows IF -> Fl -> SI2 ->  VVS2 -> SI1->VVS1 -> VS2 -> VS1

From the claims on the website we expect the categories with fewest & smallest inclusions to receive the highest clarity grades and therefore they are the most expensive. From cheapest to most expensive here are the order we expect to see from the classifications of clarity, SI -> VS -> VVS -> IF -> FL. Based on the data displayed on the graph we see that VS classifications have the highest price overall. The FL and IF prices are the lowest. The site claims that SI and VS are the best value diamonds based on price and their overall clarity rating, based on the data that appears to match up for SI because SI1 prices are the 4th most expensive and the SI2 is in one of the 3 cheapest groups. But, VS diamonds are a lower quality compared to VVS but we see that VVS is cheaper overall than VS. SI also claims that SI <VVS, or VVS should be more expensive, we can see that if we averaged SI1 and SI2 this would be true, but SI1 is more expensive than VVS2. 

**Sarah's Notes on this**   
I think Hannah's analysis above is based on a bar chart looking at distribution of price by clarity, but that seemingly creates a sum of the values. So Flawless (FL) is the second least expensive by this, but that's only because those diamonds are rarer in the dataset. I did it by average price and saw something much more in line with Blue Niles's website claims. 

There are only 3 FL diamonds and only about 50 IF diamonds, so the totals are much lower than the other clarity levels, which all have far more.

Thoughts?

```{r}
# Sarah's plot
ggplot(data, aes(x=clarity, y=price))+
  scale_y_continuous(labels = scales::comma)+
  stat_summary(fun = "mean", geom = "bar",fill="darkslategrey")+
  theme(axis.text.x = element_text(angle = 0),
        plot.title = element_text(hjust = 0.5))+
  labs(x="Clarity", y="Price",title="Distribution of Clarity vs Price")

group_mean<- aggregate(x= data$price,
                      # Specify group indicator
                      by = list(data$clarity),      
                      # Specify function (i.e. mean)
                      FUN = mean)
print(group_mean)
```


```{r}
ggplot(data, aes(x=clarity, y=price))+
  geom_violin(fill="tomato3")+
  scale_y_continuous(labels = scales::comma)+
  theme(axis.text.x = element_text(angle = 0),
        plot.title = element_text(hjust = 0.5))+
  labs(x="Clarity", y="Price", title="Distribution of Prices by Clarity")
```

From the graph above we can see that FL and VS have the highest variablity in price. Though Blue Nile claims that IF is one of the higher clarities so it should have a higher price it is has one of the lowest prices. Overall the majority of classifications are grouped around the same dollar value.

```{r}
ggplot(data, aes(x=clarity,y=price))+
  geom_point(alpha=0.5,col="darkslategrey",size=3)+
  scale_y_continuous(labels = scales::comma)+
  labs(x="Clarity", y="Price",title="Scatterplot of Blue Nile Diamond Clarity Against Price")+
  theme(plot.title = element_text(hjust = 0.5))
```
From the graph above we can see a similar trend to what is found in the violin plot. The majority of diamond prices is around the same price, regardless of the clarity of the diamond. VS1 and VVS1 have the majority of higher prices falling around $200,000 +- $50,000. VS2 had an outlier of a diamond that is around $350,000 but on average it's values are lower. While blue nile claims that FL is the highest quality when it comes to clarity and it should be most expensive 2/3 values in the data set are relatively low and fit in line with price of all other clarity classifications. One outlier has the highest price in the dataset.  

### Carat 

```{r}
meancarat<-mean(data$carat)
#Mean carat size is .813
mediancarat<-median(data$carat)
#Median carat size is .52

#Checking the spread of just carat
hist(data$carat,xlab="Carat Weight",ylab="# of Diamonds",main="Distribution of Blue Nile Diamond Carat Size", col='darkslategrey',border='white')


```
We can see that smaller carats are far more common. Diamonds under 1 carat make up over 70% of the dataset.


Average carat size is .81344  
Median carat size is .52  

```{r}
#Checking the relationship between price and carat

ggplot(data, aes(x=carat, y=price)) +
  geom_point(size=2.5, col="tomato3",alpha=0.4)+
  scale_y_continuous(labels = scales::comma)+
  labs(x="Carat Weight", y="Price",title="Scatterplot of Carat Weight Against Price of Blue Nile Diamonds")+
  theme(plot.title = element_text(hjust = 0.5))
```

BN doesn't make too many claims about carat weight, other than that carat has the biggest impact on price. This appears to be true, as price increases along an exponential curve as carat increases.

They imply that prices jump up at the .0 and .5 mark, so better value is obtained by buying right below that, (i.e. buying 0.95 carat instead of 1.0). However, I am not sure how to measure value in that sense.

It's possible they imply cut is the other most important factor. They say "[Cut] is the most important factor because it maximizes sparkle. Even a high-carat diamond with excellent color and clarity can appear lifeless and dull if the cut is poor."

Looking at that:

```{r}
ggplot(data, aes(x=cut, y=price, size=carat)) +
  geom_point(col="darkslategrey",alpha=0.4)+
  scale_y_continuous(labels = scales::comma)+
  labs(x="Carat Weight", y="Price",title="Scatterplot of Cut and Carat Against Price of Blue Nile Diamonds")+
  theme(plot.title = element_text(hjust = 0.5))
```
This seems to support the claim, since we see larger carat weight across most cuts, but larger carats seem to top the charts in each cut category. However I am not sure if it's worth further investigation, or if the findings are strong enough to include in our research.

```{r}
#Get ratio of carat weight per dollar
pricepercarat<-(data$price/data$carat)
data<-data.frame(data,pricepercarat)

data$caratratio <-round(data$pricepercarat,3)
#reordering levels in ascending order from worst to best cut
data$cut<-factor(data$cut, levels=c("Good","Very Good","Ideal","Astor Ideal"))

ggplot(data,aes(x=cut,y=pricepercarat))+
  geom_boxplot()+
  scale_y_continuous(labels = scales::comma)+
  theme(axis.text.x = element_text(),plot.title=element_text(hjust = 0.5))+
  labs(x="Cut",y="Price Per Carat", title = "Diamond Cut Against Price per Carat, with Outliers")

ggplot(data, aes(x=carat, y=pricepercarat)) +
  geom_point(size=2.5, col="darkslategrey",alpha=0.3)+
  scale_y_continuous(labels = scales::comma)+
  labs(x="Carat Weight", y="Price",title="Scatterplot of Carat Weight Against Price of Blue Nile Diamonds")+
  theme(plot.title = element_text(hjust = 0.5))

```




### Cut 

```{r}

levels(data$cut)

#creating scatterplot to see relationship between cut and price by group
ggplot(data = data, mapping = aes(x=cut,y=price))+
  geom_point(fill = "blue")+
  geom_smooth(method = lm, se = FALSE)+
  labs(x="Cut", y = "Price", title = "Relationship between Diamond Cut and Price")
#plot shows many outliers by cut (Astor Ideal appears to have the most closely clustered datapoints by price).  Difficult to see density of points in groups. #Will create additional visualizations to better explore data

#creating violin plot to more clearly see differences in cut groups
ggplot(data, aes(x=cut, y=price))+
  geom_violin()+
  labs(x="cut", y="price", title="Diamond cut vs price")

#examining the number of datapoints in each cut to better understand data
summary(data$cut)
 #     Good   Very Good       Ideal Astor Ideal 
 #        73         382         739          20 
#Astor has the smallest n of any group, while Ideal has the largest.  


#calculating the median price by cut to better understand data
median_data <- aggregate(data$price,         # Median by group
          list(data$cut),
          median)
median_data

#calculating mean price by cut to better understand data
mean_data <- aggregate(data$price,         # mean by group
          list(data$cut),
          mean)
mean_data 


#plotting median price by cut
ggplot(median_data, aes(x=Group.1, y=x))+
  geom_bar(fill= 'blue', stat="identity")+ 
  theme(axis.text.x = element_text(angle = 90), 
        plot.title = element_text(hjust = 0.5))+
  labs(x="Cut", y="Median Price", title="Median Price by Cut")

#plotting mean price by cut
ggplot(mean_data, aes(x=Group.1, y=x))+
  geom_bar(fill= 'blue', stat="identity")+ 
  theme(axis.text.x = element_text(angle = 90), 
        plot.title = element_text(hjust = 0.5))+
  labs(x="Cut", y="Average Price", title="Average Price by Cut")
```

```{r}
# Stacked
ggplot(data, aes(x=color,fill=cut))+
  geom_bar(stat="count", width=0.7)+
    theme(axis.text.x = element_text(angle = 90), 
        plot.title = element_text(hjust = 0.5))+
  labs(title = "Diamond Color by Cut",x="Diamond Color", y="Number of Diamonds")
```


```{r}
# Stacked
ggplot(data, aes(x=clarity,fill=cut))+
  geom_bar(stat="count", width=0.7)+
    theme(axis.text.x = element_text(angle = 90), 
        plot.title = element_text(hjust = 0.5))+
  labs(title = "Diamond Clarity by Cut",x="Diamond Clarity", y="Number of Diamonds")
```


### Price

Adding some info for just price if we need them

```{r}
meanprice<-mean(data$price)
#Mean price is $7,056.74
medianprice<-median(data$price)
#Median price is $1,463.50

min(data$price)

```

## Regression Code

**Developing null and alternative hypotheses: **

H0: B1 = 0
Ha: B1 <> 0 

**Description of initial linear regression **
We will start by graphing the relationship between price and carat to see if the relationship appears to be linear
```{r}
ggplot(data, aes(x=carat, y=price))+
  geom_point()+ #scatterplot
  geom_smooth(method = "lm", se = FALSE) #adds linear line 
  labs(x="Carat", y="Price", title="Effect of Diamond Carat against Price")

```
From the graph we can see that the relationship is approximately linear. Visually we can see that neither assumption 1 or 2 is met because the residuals are not evenly scattered across the horizontal line and they also do not have similar vertical variation across the plot. We have to modify the model to fit the assumptions. 

```{r}
caratregr <- lm(price~carat, data=data)
summary(caratregr)
```
From the initial linear regression we can see that 1 unit of carat increase, price increases by 25333.9.
Using our R^2 we have a 68.4% certainty that the carat affects the price.

**Description of any transformation performed for fitting the SLR model **

**Checking SLR assumptions**

```{r}
par(mfrow = c(2, 2))
plot(caratregr)
```
From the graph above we have further evidence that neither assumption is met. From the residual vs fitted graph we can see that the variance increases with the fitted Y, so assumption 1 is not met. Also the residuals are not evenly scattered across the horizontal axis so assumption 2 is not met. From this plot we will choose to perform a log transformation with a lambda value less than 1. 

```{r}
library(MASS) ##to use boxcox function
MASS::boxcox(caratregr, lambda = seq(-0.5, 0.5, 1/10))
```
Using the box-cox plot we can narrow down the range of our lambda to choose. Since 1 is not inside the CI we can confirm that we can transform the y (price) with a log transformation. We will zoom into the graph to choose a lambda that falls within the 95 % confidence interval (between the vertical dotted lines). 

```{r}
library(MASS) ##to use boxcox function
MASS::boxcox(caratregr, lambda = seq(0.2, 0.4, 1/10))
```
Based on the Box Cox plot, raising the response variable to power of a value within the confidence interval should work. 
Based on the graph above we will raise the response variable to 0.3. Raise the response variable to the power of the lambda value we chose. 
```{r}
#transform y 
data$newy<-log(data$price)

#regress new y against x
result <- lm(newy~carat, data = data)

#create a new residual plot 
par(mfrow=c(2,2))
plot(result)
```


**Commentary on choices for transformation **
From the residual plot we can see that the variance of the residuals improved and the variance is more constant when moving from left to right on the graph. 

Based on the residual plot the residuals are still not evenly scattered across the horizontal axis, indicating that there is a non-linear relationship between the variables. So we will need to transform carat, the x variable, next. In order to determine the x value we will need to create a scatter plot of our adjusted y value against x.

```{r}
ggplot2::ggplot(data, aes(x=carat,y=newy))+
  geom_point()+
  geom_smooth(method = "lm", se=FALSE)+
  labs(x="Carat", y="Priceˆ0.3",
  title="Priceˆ0.3 against Carat")

```

Based on the graph we will choose to use a log(x) transformation to the carat.

Regress y^2 against x* and create the corresponding residual plot.
```{r}
data$caratstar<-log(data$carat)

ggplot(data, aes(x=caratstar, y=newy))+
  geom_point()+
  geom_smooth(method = "lm", se=FALSE)+
  labs(x="Log of Carat", y="Log of Price", title="Effect of Regressed Diamond Carat against Regressed Price")

```
Based on the scatter plot it appears that both assumption 1 and 2 are met. To verify we will look at the residual plot. 

```{r}
final_result <- lm(newy~caratstar, data = data)

#create a new residual plot 
par(mfrow=c(2,2))
plot(final_result)
```
From the residual vs fitted graph we see that the variance of the residuals improved and is more constant. The residuals are evenly scattered across the horizontal axis so both assumptions are met. 

We no longer need to transform the variables

**Testing hypothesis **
From the scatterplot we verify that positive linear association exists and assumptions 1 and 2 are met. We do not need see any pattern in the data that warrants further investigation.

```{r}
cor(data$caratstar, data$newy)
```
The correlation between the regressed price and carat is 0.9770805. This indicates that are assumptions from the scatterplot are correct and there is a strong positive linear relationship between the two variables. 

```{r}
summary(final_result)
```
B1^ = 1.944020
B^0 = 8.521208
R^2 = 0.9547
σ^2 = 0.2761^2

For each additional carat, the predicted price increases by $1.94. ***units???***

When the number of carats is 0 the predicted price of the ring will be $8.52

**Walking through calculations for: **

**F-test** 
```{r}
anova.tab <- anova(final_result)
anova.tab
```
The anova F  statistic is 25535. The hypotheses are H0 = B1 =0 and Ha <> 0. Since the p-value is small, we reject the null hypothesis. This supports the claim that there is a linear association between price and carat. 

**P-test **


**Assessing R squared **
The R^2 is 0.9547.  This means that about 95.47% of the variation in the price can be explained by the number of carats for diamonds.


**Final linear formula **
y^ = 8.521208 + 1.944020x

**Commentary on carat’s relationship to diamond price **
